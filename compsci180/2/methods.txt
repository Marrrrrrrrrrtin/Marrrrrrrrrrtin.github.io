Introduction
    In this project, we have 3 digitized glass plate images for each image, and our task is to align the 3 images to the best position to reconstruct the colorful version of the images.

My brief pipeline:
    1. Pyramid images into half size with Gaussian Blur
    2. Get the gradient of the images in each layer for textures
    3. Define the matrices of the similarity, where I chose NCC
    4. Set blue as the reference image, and find the best shift for red and green
    4. Recursively search the best shift for each layer of Gaussian Blur
    5. Shift the red and green images, and combine the RGB together for the final image
    6. Crop the edges to avoid the noisy border
    7. If the images are not stored in unit8, I use percentile to transfer them into uint8 for standard jpg

Details for each step:
    1. Pyramid: I choose 5 * 5 window to calculate the result, and use [1,4,6,4,1] as convolution matrix instead of e directly for higher computing efficiency. As the G(x,y) = G(x)G(y), the blured images are computed by axis respectively and combined together
    2. Gradient is calculated by convolution, with [[-1,0,1], [-2,0,2], [-1,0,1]]. As the computation and padding part is similar to the Gaussian Blur part, this computation is achieved by sobel function.
    3. The reason why I chose NCC is that it shows stronger robust. I used MSE at the beginning but the performance was really bad.
    4. I choose blue because it's the same as the starter code.
    5, 6. Call functions we defined previously and use shift to combine them together

Parameters:
    1. The number of layers: it really depends on the images. For smaller images, like jpg, we need smaller levels, like 2 or 3, to prevent losing too much information during the pyramid part. If the level is too high, the align will be really random and vary signicantly.
    2. Searching radius: for most images, I set the final level to 8, and others to 1 or 2, as it is good enough with really high efficient. However, for some images, I set the final level to 10, and others to 3, as their performance was really bad at beginning. However, I'm still not sure about the how to determine the best balance between the performance and efficiency, and the current method is just by experiment to see the result manually. 

Notes:
    1. At the beginning, I testing all my work on a Jupyter Notebook for more flexibilities on different ideas and parameters. As the result gets proper, I rewrite the Notebook into Python class for easier future use
    2. The largest challenge was searching the best parameters, as the same parameters performe really differently on different images. The way to solve it is to transfer those images by classification. I use the balanced parameters to align most of tif and jpg images respectively as they should use different numbers of layers of pyramid. For the rest images, if the final result is really bad, I increase the search radius of the final level for larger searching areas. For images with little ghost, I increase the search radius for other levels as they can refine the search areas. 



